{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/StudentData/hw2_data/train_images/train'\n",
    "test_path = '/StudentData/hw2_data/test_images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loader for Image\n",
    "\n",
    "class ImageFolderWithName(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.transform = transform\n",
    "        self.images_paths = glob(root + '/*.jpg')\n",
    "        self.labels = torch.LongTensor([int(basename(image_path).split('_')[1].split('.')[0]) for image_path in self.images_paths])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images_paths[idx]\n",
    "        image = self.transform(Image.open(image_path))\n",
    "        label = self.labels[idx]\n",
    "        return (image, label, basename(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225))  \n",
    "])    \n",
    "\n",
    "root_train = '/StudentData/hw2_data/train_images/'\n",
    "root_test = '/StudentData/hw2_data/test_images/'\n",
    "image_datasets_train_1 = ImageFolderWithName(root_train, transform=transform_train)\n",
    "image_datasets_train_2 = ImageFolderWithName(root_train, transform=transform_test)\n",
    "image_datasets_test = ImageFolderWithName(root_test, transform=transform_test)\n",
    "\n",
    "train_loader_1 = data.DataLoader(image_datasets_train_1,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True) \n",
    "\n",
    "train_loader_2 = data.DataLoader(image_datasets_train_2,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False) \n",
    "\n",
    "test_loader = data.DataLoader(image_datasets_test,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), \n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "            \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(2))\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(2))\n",
    "  \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AvgPool2d(2))\n",
    "    \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AvgPool2d(2))\n",
    "    \n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.AvgPool2d(2))\n",
    "        \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(64, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.AvgPool2d(2))\n",
    "        \n",
    "        self.linearLayers = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=144, out_features=2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linearLayers(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gpu(x):\n",
    "    return x.cuda() if torch.cuda.is_available() else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_acc(labels, outputs):\n",
    "    return accuracy_score(labels, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ROC(labels, outputs):\n",
    "    return roc_auc_score(labels, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_F1(labels, outputs):\n",
    "    return f1_score(labels, outputs, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  698642\n",
      "Num of trainable parameters : 698642\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn = to_gpu(cnn)\n",
    "\n",
    "criterion = to_gpu(nn.CrossEntropyLoss())\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "print('number of parameters: ', sum(param.numel() for param in cnn.parameters()))\n",
    "print(f'Num of trainable parameters : {sum(p.numel() for p in cnn.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [200/570], Loss: 0.4870\n",
      "Epoch: [1/10], Step: [400/570], Loss: 0.2336\n",
      "train acc:  0.9219015280135824\n",
      "test acc:  0.9277029247453171\n",
      "Epoch: [2/10], Step: [200/570], Loss: 0.1767\n",
      "Epoch: [2/10], Step: [400/570], Loss: 0.1991\n",
      "train acc:  0.9034996440111726\n",
      "test acc:  0.9074926059809398\n",
      "Epoch: [3/10], Step: [200/570], Loss: 0.2604\n",
      "Epoch: [3/10], Step: [400/570], Loss: 0.2868\n",
      "train acc:  0.9284736294430144\n",
      "test acc:  0.9362471245481433\n",
      "Epoch: [4/10], Step: [200/570], Loss: 0.1799\n",
      "Epoch: [4/10], Step: [400/570], Loss: 0.2984\n",
      "train acc:  0.9361958486225971\n",
      "test acc:  0.9410121590535656\n",
      "Epoch: [5/10], Step: [200/570], Loss: 0.2225\n",
      "Epoch: [5/10], Step: [400/570], Loss: 0.1499\n",
      "train acc:  0.941179692206583\n",
      "test acc:  0.9477489319750246\n",
      "Epoch: [6/10], Step: [200/570], Loss: 0.1831\n",
      "Epoch: [6/10], Step: [400/570], Loss: 0.1325\n",
      "train acc:  0.9479708636836629\n",
      "test acc:  0.9465987512323365\n",
      "Epoch: [7/10], Step: [200/570], Loss: 0.1886\n",
      "Epoch: [7/10], Step: [400/570], Loss: 0.1717\n",
      "train acc:  0.9433156251711484\n",
      "test acc:  0.9484061781137035\n",
      "Epoch: [8/10], Step: [200/570], Loss: 0.3631\n",
      "Epoch: [8/10], Step: [400/570], Loss: 0.1836\n",
      "train acc:  0.9507092392792595\n",
      "test acc:  0.9536641472231351\n",
      "Epoch: [9/10], Step: [200/570], Loss: 0.1129\n",
      "Epoch: [9/10], Step: [400/570], Loss: 0.2154\n",
      "train acc:  0.9542143600416233\n",
      "test acc:  0.9571146894511995\n",
      "Epoch: [10/10], Step: [200/570], Loss: 0.1404\n",
      "Epoch: [10/10], Step: [400/570], Loss: 0.2046\n",
      "train acc:  0.9572265731967796\n",
      "test acc:  0.9590864278672363\n"
     ]
    }
   ],
   "source": [
    "loss_test_arr = []\n",
    "loss_train_arr = []\n",
    "acc_train_arr = []\n",
    "acc_test_arr = []\n",
    "ROC_train_arr = []\n",
    "ROC_test_arr = []\n",
    "F1_train_arr = []\n",
    "F1_test_arr = []\n",
    "names_arr = []\n",
    "for epoch in range(num_epochs):\n",
    "    batchs_loss_train = []\n",
    "    batchs_loss_test = []\n",
    "    batchs_acc_train = []\n",
    "    batchs_acc_test = []\n",
    "    labels_train_arr = []\n",
    "    labels_test_arr = []\n",
    "    predicted_train = []\n",
    "    predicted_test = []\n",
    "    cnn.train()\n",
    "    for i, (images, labels, names) in enumerate(train_loader_1):\n",
    "        images = to_gpu(images)\n",
    "        labels = to_gpu(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 200 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(image_datasets_train_1)//batch_size, loss.item()))\n",
    "    \n",
    "    cnn.eval()\n",
    "    for images_test, labels_test, names_test in train_loader_2:\n",
    "        images_test = to_gpu(images_test)\n",
    "        labels_test = to_gpu(labels_test)\n",
    "        outputs_test = cnn(images_test)\n",
    "        foo, predicted = torch.max(outputs_test.data, 1)\n",
    "        predicted_train = np.append(predicted_train, predicted.cpu().numpy())\n",
    "        labels_train_arr = np.append(labels_train_arr, labels_test.cpu().numpy())\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "        batchs_loss_train.append((loss.item())*len(images_test))\n",
    "    \n",
    "    loss_train_arr.append(sum(batchs_loss_train) / len(image_datasets_train_2))\n",
    "    acc_train_arr.append(evaluation_acc(labels_train_arr, predicted_train))\n",
    "    ROC_train_arr.append(evaluation_ROC(labels_train_arr, predicted_train))\n",
    "    F1_train_arr.append(evaluation_F1(labels_train_arr, predicted_train))\n",
    "    print(\"train acc: \", acc_train_arr[-1])\n",
    "    \n",
    "    for images_test, labels_test, names_test in test_loader:\n",
    "        images_test = to_gpu(images_test)\n",
    "        labels_test = to_gpu(labels_test)\n",
    "        outputs_test = cnn(images_test)\n",
    "        foo, predicted = torch.max(outputs_test.data, 1)\n",
    "        predicted_test = np.append(predicted_test, predicted.cpu().numpy())\n",
    "        labels_test_arr = np.append(labels_test_arr, labels_test.cpu().numpy())\n",
    "        names_arr.append(names_test)\n",
    "        loss_test = criterion(outputs_test, labels_test)\n",
    "        batchs_loss_test.append((loss_test.item())*len(images_test))\n",
    "    \n",
    "    loss_test_arr.append(sum(batchs_loss_test) / len(image_datasets_test))\n",
    "    acc_test_arr.append(evaluation_acc(labels_test_arr, predicted_test))\n",
    "    ROC_test_arr.append(evaluation_ROC(labels_test_arr, predicted_test))\n",
    "    F1_test_arr.append(evaluation_F1(labels_test_arr, predicted_test))\n",
    "    print(\"test acc: \", acc_test_arr[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"loss_test7.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(loss_test_arr, fp)\n",
    "with open(\"loss_train7.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(loss_train_arr, fp)\n",
    "with open(\"acc_train7.txt\", \"wb\") as fp:     \n",
    "    pickle.dump(acc_train_arr, fp)\n",
    "with open(\"acc_test7.txt\", \"wb\") as fp: \n",
    "    pickle.dump(acc_test_arr, fp)\n",
    "with open(\"ROC_train7.txt\", \"wb\") as fp: \n",
    "    pickle.dump(ROC_train_arr, fp)\n",
    "with open(\"ROC_test7.txt\", \"wb\") as fp: \n",
    "    pickle.dump(ROC_test_arr, fp)\n",
    "with open(\"F1_train7.txt\", \"wb\") as fp: \n",
    "    pickle.dump(F1_train_arr, fp)\n",
    "with open(\"F1_test7.txt\", \"wb\") as fp: \n",
    "    pickle.dump(F1_test_arr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"cnn_better_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
